# Школа 109

## Wpull
Для сбора данных сайтов использовалась библиотека wpull. В результате работы получился архив, который можно открыть в ReplayWeb.page
<img width="2559" height="1299" alt="изображение" src="https://github.com/user-attachments/assets/33e6ede6-3d69-4318-93d9-95bd7d9afab1" />
Как можно видеть по скриншоту, сайт в целом успешно архивировался, так как текстовое содержимое и дизайн сохранены. Однако медиа-файлы не были сохранены в полном объеме, а также при попытке открыть некоторые страницы вылезает ошибка 404 (но она же возникает и при попытке открыть эти страницы в браузере, поэтому эти страницы скорее всего были удалены с сайта, но ссылки на них сохранились).

## ArchiveReady
На момент 08.12.2025 у меня не открывается сайт на ArchiveReady, поэтому невозможно предоставить скриншот результата, однако ранее, когда данный сайт проверялся, то показывалось 76%.

## Metawarc
1. analyze\
   Результаты работы этой команды представлены в файле metawarc.png. Наибольшую долю по весу файлов занимают файлы javascript, что ожидаемо, так как сайт скорее всего использует много различных блоков, написанных на javascript. Наибольшую долю по количеству файлов занимают изображения в формате svg и xml.
2. metadata\
   В результате работы этой команды был получен файле metadata.jsonl. В файле errors.txt указаны ошибки, которые возникли в ходе работы команды.
3. index\
   В результате работы был создан файл metawarc.db.
